{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4bd38f6",
   "metadata": {},
   "source": [
    "# Cross Validation in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bcd0ca",
   "metadata": {},
   "source": [
    "* Cross-validation is a widely used model evaluation technique that helps assess how well a machine learning model is likely to perform on unseen data.\n",
    "\n",
    " * It works by dividing the dataset into multiple segments (or folds), where the model is trained on a portion of the data and tested on the remaining part.\n",
    " \n",
    " * This process is repeated multiple times, each time using a different fold as the test set. \n",
    " * The performance metrics from each iteration are then averaged, providing a more reliable and unbiased estimate of the model’s ability to generalize to new data.\n",
    "\n",
    "\n",
    " **The main purpose of cross validation is to prevent overfitting.**\n",
    "\n",
    " If you want to make sure your machine learning model is not just memorizing the training data but is capable of adapting to real-world data cross-validation is a commonly used technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891920e5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f97d980",
   "metadata": {},
   "source": [
    "## Types of Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbaff14",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01127886",
   "metadata": {},
   "source": [
    "### 1. Holdout Validation\n",
    "\n",
    "\n",
    "  Holdout Validation is a simple technique where the dataset is split into two parts—typically 50% for training and 50% for testing. The model is trained on the training set and evaluated on the testing set.\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "  * Randomly divide the dataset into two portions.\n",
    "  * Train the model on one portion.\n",
    "  * Test the model on the other portion.\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "  * Easy to implement.\n",
    "  * Fast and requires less computational time.\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "Might miss key patterns if important data is in the testing set.\n",
    "Can result in higher bias as the model is trained on only half of the data.\n",
    "The evaluation might vary significantly depending on how the data was split.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcfbb52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout Validation Accuracy: 0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "### 1. Holdout Validation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Perform Holdout Validation: 50% training, 50% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Train a classifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Holdout Validation Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5902a4ae",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Leave-One-Out Cross-Validation (LOOCV)\n",
    "\n",
    " LOOCV is an exhaustive cross-validation method where one data point is left out for testing, and the rest is used for training. This is repeated for every data point.\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "  - For a dataset of n samples, train the model on n - 1 samples.\n",
    "  - Test on the one left-out sample.\n",
    "  - Repeat this process n times, each time leaving out a different sample.\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "  - Uses nearly the entire dataset for training, leading to low bias.\n",
    "  - Effective when datasets are very small.\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "  - High variance in results, as testing is done on a single point at a time.\n",
    "  - Extremely computationally expensive, especially with large datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34d39cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOCV Accuracy: 0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Initialize Leave-One-Out cross-validator\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Initialize model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Store predictions and true values\n",
    "predictions = []\n",
    "true_values = []\n",
    "\n",
    "# Perform LOOCV\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions.append(y_pred[0])\n",
    "    true_values.append(y_test[0])\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(true_values, predictions)\n",
    "print(\"LOOCV Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eea6ffe",
   "metadata": {},
   "source": [
    "### 3. Stratified Cross-Validation\n",
    "\n",
    " Stratified Cross-Validation is a variation of K-Fold Cross-Validation designed for classification problems, especially imbalanced datasets. It ensures that each fold maintains the same class distribution as the entire dataset.\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "  - The dataset is split into k folds, keeping the class proportions the same in each fold.\n",
    "  - Train the model on k - 1 folds and test on the remaining fold.\n",
    "  - Repeat the process k times, ensuring each fold is used once as the test set.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "  - Ensures each fold is representative of the overall class distribution, reducing bias towards over-represented classes.\n",
    "  - Improves model stability and generalization on imbalanced datasets.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "  - More complex to implement than basic K-Fold.\n",
    "  - Might still be computationally heavy for large datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "326ab796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified Cross-Validation Accuracy for each fold: [1.0, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9333333333333333]\n",
      "Average Accuracy: 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Define StratifiedKFold with 5 splits\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Track scores\n",
    "scores = []\n",
    "\n",
    "# Perform Stratified Cross-Validation\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    scores.append(accuracy)\n",
    "\n",
    "# Print results\n",
    "print(\"Stratified Cross-Validation Accuracy for each fold:\", scores)\n",
    "print(\"Average Accuracy:\", np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1d33fc",
   "metadata": {},
   "source": [
    "### 4. K-Fold Cross-Validation\n",
    "\n",
    "K-Fold Cross-Validation is a widely used cross-validation method where the dataset is split into k equally sized folds. The model is trained on k - 1 folds and tested on the remaining fold. This process is repeated k times, each time with a different fold used as the test set.\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "  * Divide the data into k folds.\n",
    "  * In each iteration, use k - 1 folds for training and the remaining fold for testing.\n",
    "  * Average the results from all k iterations for the final performance metric.\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "  * Provides a balanced trade-off between bias and variance.\n",
    "  * More efficient than LOOCV.\n",
    "  * Suitable for most general datasets.\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "  * Still requires k iterations, which can be time-consuming with large datasets.\n",
    "  * Class imbalance might still be an issue unless used with stratification.\n",
    "\n",
    "**Best Practice Tip:**\n",
    "\n",
    "  * Typically, k = 10 is considered a good balance, offering reliable performance estimates without excessive computation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71d1949f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold Cross-Validation Accuracy for each fold: [1.0, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667]\n",
      "Average Accuracy: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Define KFold with 5 splits\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Track scores\n",
    "scores = []\n",
    "\n",
    "# Perform K-Fold Cross-Validation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    scores.append(accuracy)\n",
    "\n",
    "# Print results\n",
    "print(\"K-Fold Cross-Validation Accuracy for each fold:\", scores)\n",
    "print(\"Average Accuracy:\", np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098ae47a",
   "metadata": {},
   "source": [
    "### 5. Out-of-Bag (OOB) Evaluation\n",
    "\n",
    "Out-of-Bag (OOB) evaluation is a built-in validation technique used specifically with ensemble methods like Random Forests. It allows the model to validate itself using data samples that were not included in the bootstrap sample during training.\n",
    "\n",
    "**How it works:**\n",
    "\n",
    " * In ensemble models like **Random Forest**, each tree is trained on a random sample (with replacement) of the training data — this is called **bootstrap sampling**.\n",
    "\n",
    " * On average, about 63% of the data is used to train each tree; the remaining 37% of the data (not included) is called the Out-of-Bag samples.\n",
    "\n",
    " * These OOB samples are used to test the tree’s predictions, effectively providing a validation set without explicitly splitting the dataset.\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    " * No need to set aside a separate validation set.\n",
    " * Efficient use of data — training and validation are done simultaneously.\n",
    " * Reduces computation by eliminating the need for manual cross-validation in many cases.\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    " * Only available with **bagging-based algorithms** (like Random Forest).\n",
    " * May not be as stable or reliable as k-fold cross-validation on small datasets.\n",
    " * Not suitable for all types of models (e.g., boosting, linear models).\n",
    "\n",
    "**Best Practice Tip:**\n",
    "\n",
    "Enable **oob_score=True** when training a Random Forest in scikit-learn to automatically calculate the OOB score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb162f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Score: 0.9428571428571428\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data (just for comparing OOB score with test accuracy)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize Random Forest with OOB enabled\n",
    "rf = RandomForestClassifier(n_estimators=100, oob_score=True, bootstrap=True, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the OOB score\n",
    "print(\"OOB Score:\", rf.oob_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
