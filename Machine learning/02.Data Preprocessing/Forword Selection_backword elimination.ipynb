{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6176ef78",
   "metadata": {},
   "source": [
    "## Forward Selection\n",
    "\n",
    " * Forward Selection starts with an empty model and adds features one by one, choosing the feature that most improves the model performance (e.g., lowest AIC, highest R², etc.) in each iteration.\n",
    "\n",
    " * This method is greedy and deterministic, useful when we want to quickly build a performant model using only the most significant features.\n",
    "\n",
    " **How it Works:**\n",
    "\n",
    "   * Start with an empty model.\n",
    "\n",
    "   * For each feature not already in the model:\n",
    "\n",
    "   * Train the model by adding that feature.\n",
    "\n",
    "   * Evaluate performance using a metric (e.g., accuracy, R², AIC).\n",
    "\n",
    "   * Add the feature that improves performance the most.\n",
    "\n",
    "   * Repeat steps 2–3 until:\n",
    "\n",
    "     * No significant performance gain is observed, or\n",
    "     * A pre-defined number of features is reached.\n",
    "\n",
    "\n",
    " **When to Use:**\n",
    "\n",
    "  * When model simplicity and interpretability are important.\n",
    "\n",
    "  * When the dataset has many irrelevant features.\n",
    "  * When computational power is limited.\n",
    "\n",
    "\n",
    " **Advantages:**\n",
    "\n",
    "  * Efficient with a smaller feature set.\n",
    "\n",
    "  * Helps avoid overfitting by selecting only the most informative features.\n",
    "\n",
    " **Limitations:**\n",
    "\n",
    "  * Can miss combinations of features that only work well together.\n",
    "\n",
    "  * May be time-consuming for high-dimensional datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205ffe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load California Housing dataset\n",
    "data = fetch_california_housing()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name=\"MedHouseValue\")\n",
    "\n",
    "def forward_selection(X, y):\n",
    "    initial_features = []\n",
    "    remaining_features = list(X.columns)\n",
    "    best_score = float('inf')\n",
    "    selected_features = []\n",
    "\n",
    "    while remaining_features:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remaining_features:\n",
    "            model = sm.OLS(y, sm.add_constant(X[initial_features + [candidate]])).fit()\n",
    "            aic = model.aic\n",
    "            scores_with_candidates.append((aic, candidate))\n",
    "\n",
    "        scores_with_candidates.sort()\n",
    "        best_new_score, best_candidate = scores_with_candidates[0]\n",
    "\n",
    "        if best_new_score < best_score:\n",
    "            remaining_features.remove(best_candidate)\n",
    "            initial_features.append(best_candidate)\n",
    "            best_score = best_new_score\n",
    "            selected_features.append(best_candidate)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "selected_forward = forward_selection(X, y)\n",
    "print(\"Selected Features using Forward Selection:\\n\", selected_forward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c316232",
   "metadata": {},
   "source": [
    "# Backward Elimination\n",
    "\n",
    "\n",
    " * Backward Elimination starts with all features included and removes the least significant one at each step, based on statistical metrics or model performance.\n",
    "\n",
    "**How it Works:**\n",
    "\n",
    "  1. Begin with all available features in the model.\n",
    "\n",
    "  2. Train the model and evaluate the importance or significance of each feature.\n",
    "\n",
    "  3. Remove the least significant feature (e.g., highest p-value or least effect on performance).\n",
    " \n",
    "  4. Repeat steps 2–3 until:\n",
    "     * All remaining features are statistically significant, or\n",
    "     * Removing more features worsens the model.\n",
    "\n",
    "**When to Use:**\n",
    "\n",
    " * When all features are assumed to be relevant initially.\n",
    " \n",
    " * When dataset is moderate in size (as it's computationally expensive).\n",
    "\n",
    " * To find the most influential subset of features.\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "  * Considers the full model context initially.\n",
    "\n",
    "  * Captures interactions between features that may be lost in forward selection.\n",
    "\n",
    "**Limitations:**\n",
    "\n",
    "  * Computationally expensive with large feature sets.\n",
    "\n",
    "  * Risk of retaining redundant features early on.\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f635cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load California Housing dataset\n",
    "data = fetch_california_housing()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name=\"MedHouseValue\")\n",
    "\n",
    "\n",
    "def backward_elimination(X, y, significance_level=0.05):\n",
    "    features = X.columns.tolist()\n",
    "    while len(features) > 0:\n",
    "        X_model = sm.add_constant(X[features])\n",
    "        model = sm.OLS(y, X_model).fit()\n",
    "        p_values = model.pvalues.iloc[1:]  # exclude intercept\n",
    "        max_p_value = p_values.max()\n",
    "        if max_p_value > significance_level:\n",
    "            excluded_feature = p_values.idxmax()\n",
    "            features.remove(excluded_feature)\n",
    "        else:\n",
    "            break\n",
    "    return features\n",
    "\n",
    "selected_backward = backward_elimination(X, y)\n",
    "print(\"Selected Features using Backward Elimination:\\n\", selected_backward)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
